{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304e3183-ef7f-4283-9d31-28d3aad94cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import io\n",
    "from pytorch_models_imp.my_transformer import SelfAttention as mySelfAttention\n",
    "from pytorch_models_imp.my_transformer import TransformerBlock as myTransformerBlock\n",
    "from pytorch_models_imp.my_transformer import Encoder as myEncoder\n",
    "from pytorch_models_imp.my_transformer import DecoderBlock as myDecoderBlock\n",
    "from pytorch_models_imp.my_transformer import Decoder as myDecoder\n",
    "from pytorch_models_imp.my_transformer import Transformer as myTransformer\n",
    "from pytorch_models_imp.transformer import SelfAttention, TransformerBlock, Encoder, DecoderBlock, Decoder, Transformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n",
    "train_urls = ('train.de.gz', 'train.en.gz')\n",
    "val_urls = ('val.de.gz', 'val.en.gz')\n",
    "test_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89e71a6-ce3e-4338-b648-4d409ce4b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd35744-8e2c-4f39-a3db-9aa40b1e272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
    "val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
    "test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe49155-cf2a-45f6-ad6a-e62aa3308913",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8abab3-cf74-4259-b88f-24407397897f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "342e5941-6ad4-462a-80e9-f54acccf476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(filepath, tokenizer):\n",
    "    with io.open(filepath, encoding=\"utf8\") as f:\n",
    "        for string_ in f:\n",
    "            yield tokenizer(string_)\n",
    "            \n",
    "de_vocab = build_vocab_from_iterator(yield_tokens(train_filepaths[0], de_tokenizer), specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "de_vocab.set_default_index(de_vocab[\"<unk>\"])\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(yield_tokens(train_filepaths[1], en_tokenizer), specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "en_vocab.set_default_index(de_vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fc47bc-8314-4e43-aa33-edc4decb3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(filepaths):\n",
    "    raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
    "    raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
    "    data = []\n",
    "    for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\n",
    "        de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],\n",
    "                                dtype=torch.long)\n",
    "        en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n",
    "                                dtype=torch.long)\n",
    "        data.append((de_tensor_, en_tensor_))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63de4ecd-5c3b-44da-b4c5-9160c2dd0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_process(train_filepaths)\n",
    "val_data = data_process(val_filepaths)\n",
    "test_data = data_process(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8286fec-3779-4c42-b580-c94ef5758c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "PAD_IDX = de_vocab['<pad>']\n",
    "BOS_IDX = de_vocab['<bos>']\n",
    "EOS_IDX = de_vocab['<eos>']\n",
    "\n",
    "TARGET_PAD_INDX = en_vocab[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e7a7bb-07bf-4a7a-a516-2aa6e9cfdf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD: 1, BOS: 2, EOS: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"PAD: {PAD_IDX}, BOS: {BOS_IDX}, EOS: {EOS_IDX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ecb336c-5baf-4653-ba84-d05a18617c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    de_batch, en_batch = [], []\n",
    "    for (de_item, en_item) in data_batch:\n",
    "        de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "    de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "    return de_batch, en_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16631580-d72d-419c-b001-86bf40652ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=True, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68cdc1-0f0b-44f2-a667-ffcfbf8219b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e46afe9f-45b5-4bc9-b7d7-04bc8172fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "de, en = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "154a06a8-9664-439a-9632-8f2cbcccccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_trans = de.T\n",
    "en_trans = en.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f82490a-61c3-4de0-b9dd-79fbf31cbcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = nn.Embedding(len(de_vocab), 256)\n",
    "de_trans_emb = e(de_trans)\n",
    "en_trans_emb = e(en_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "853e141b-74da-48ed-927c-1e4f09424da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(de_vocab)\n",
    "TRG_VOCAB_SIZE = len(en_vocab)\n",
    "\n",
    "SRC_PAD_INDX = de_vocab['<pad>']\n",
    "TRG_PAD_INDX = en_vocab['<pad>']\n",
    "\n",
    "NUM_LAYERS = 3\n",
    "HEADS = 8\n",
    "EMBED_SIZE = 256\n",
    "FORWARD_EXPANSION = 3\n",
    "DROPOUT = 0.1\n",
    "DEVICE = \"cpu\"\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b2571e-6c15-498f-a29a-4abf52be92e9",
   "metadata": {},
   "source": [
    "### Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f00e8c22-424f-438f-9682-605fccd0c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_self_attention = mySelfAttention(EMBED_SIZE, heads=HEADS)\n",
    "self_attention = SelfAttention(EMBED_SIZE, heads=HEADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbf32080-a091-44dd-9cf4-bad070cac380",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attention_out = self_attention(de_trans_emb, de_trans_emb, de_trans_emb, None)\n",
    "my_self_attention_out = my_self_attention(de_trans_emb, de_trans_emb, de_trans_emb, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2180c938-6608-4808-9031-b88b91723112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My max output: 0.6589629650115967. Size of the model: 68960\n",
      "Their max output: 0.6907479763031006. Size of the model: 68864\n"
     ]
    }
   ],
   "source": [
    "print(\"My max output: {0}. Size of the model: {1}\".format(my_self_attention_out.max(), calculate_params(my_self_attention)))\n",
    "print(\"Their max output: {0}. Size of the model: {1}\".format(self_attention_out.max(), calculate_params(self_attention)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3718a9b2-7c20-4f33-a7a4-14d71dbb3ec6",
   "metadata": {},
   "source": [
    "### Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a3eeae7-49c4-468e-bb71-6fc2b2e26b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_trans_block = myTransformerBlock(EMBED_SIZE, HEADS, FORWARD_EXPANSION, DROPOUT)\n",
    "their_trans_block = TransformerBlock(EMBED_SIZE, HEADS, forward_expansion=FORWARD_EXPANSION, dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe144c87-71fc-4a44-9edd-6ae4fed69287",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_out = my_trans_block(de_trans_emb, de_trans_emb, de_trans_emb, None)\n",
    "their_out = their_trans_block(de_trans_emb, de_trans_emb, de_trans_emb, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ccafa51-3271-4462-b22d-725f15304893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My max output: 5.1221418380737305. Size of the model: 464224\n",
      "Their max output: 5.242747783660889. Size of the model: 464128\n"
     ]
    }
   ],
   "source": [
    "print(\"My max output: {0}. Size of the model: {1}\".format(my_out.max(), calculate_params(my_trans_block)))\n",
    "print(\"Their max output: {0}. Size of the model: {1}\".format(their_out.max(), calculate_params(their_trans_block)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10348967-40ec-439d-a28b-a42ddfc30bfb",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2c680ea-079e-402c-a4f8-da6423c09905",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_encoder = myEncoder(SRC_VOCAB_SIZE, EMBED_SIZE, NUM_LAYERS, HEADS, FORWARD_EXPANSION, DROPOUT, MAX_LENGTH)\n",
    "their_encoder = Encoder(SRC_VOCAB_SIZE, EMBED_SIZE, NUM_LAYERS, HEADS, DEVICE, FORWARD_EXPANSION, DROPOUT, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ac5ca80-4c7e-4b28-adf5-372f6b5147b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_out = my_encoder(de_trans, None)\n",
    "their_out = their_encoder(de_trans, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d21ecf43-1737-4314-b0f7-0b995611a171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My max output: 5.011844158172607. Size of the model: 6337312\n",
      "Their max output: 5.962292194366455. Size of the model: 6337024\n"
     ]
    }
   ],
   "source": [
    "print(\"My max output: {0}. Size of the model: {1}\".format(my_out.max(), calculate_params(my_encoder)))\n",
    "print(\"Their max output: {0}. Size of the model: {1}\".format(their_out.max(), calculate_params(their_encoder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5cf906-ec40-4961-ab04-47f3f0c7fbf4",
   "metadata": {},
   "source": [
    "### Decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20f8014e-b4b9-42a1-b765-89ff37603e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_decoder_block = myDecoderBlock(EMBED_SIZE, HEADS, FORWARD_EXPANSION, DROPOUT)\n",
    "their_decoder_block = DecoderBlock(EMBED_SIZE, HEADS, FORWARD_EXPANSION, DROPOUT, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5358f8d5-13d2-40b2-a252-0c14bb141eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_out = my_decoder_block(de_trans_emb, de_trans_emb, de_trans_emb, None, None)\n",
    "their_out = their_decoder_block(de_trans_emb, de_trans_emb, de_trans_emb, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d96fac3f-3f51-4450-a190-9845e6c134ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My max output: 4.791199684143066. Shape: torch.Size([128, 36, 256]). Size of the model: 533696\n",
      "Their max output: 6.233399868011475. Shape: torch.Size([128, 36, 256]). Size of the model: 533504\n"
     ]
    }
   ],
   "source": [
    "print(\"My max output: {0}. Shape: {1}. Size of the model: {2}\".format(my_out.max(), my_out.shape, calculate_params(my_decoder_block)))\n",
    "print(\"Their max output: {0}. Shape: {1}. Size of the model: {2}\".format(their_out.max(), my_out.shape, calculate_params(their_decoder_block)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a952919-ffcf-452a-bf2d-dd851f2f591a",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9848562d-97c3-4bfe-8f59-cf5d44e1ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_decoder = myDecoder(TRG_VOCAB_SIZE, EMBED_SIZE, NUM_LAYERS, HEADS, FORWARD_EXPANSION, DROPOUT, MAX_LENGTH)\n",
    "their_decoder = Decoder(TRG_VOCAB_SIZE, EMBED_SIZE, NUM_LAYERS, HEADS, FORWARD_EXPANSION, DROPOUT, DEVICE, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e4975bb-261b-48a9-964e-ee4680638642",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_out = my_decoder(en_trans, en_trans_emb, None, None)\n",
    "their_out = their_decoder(en_trans, en_trans_emb, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e5b4f1d-cc9b-4d9e-bc2c-872b3042d0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My max output: 3.164764881134033. Shape: torch.Size([128, 36, 10838]). Size of the model: 7186582\n",
      "Their max output: 3.1691977977752686. Shape: torch.Size([128, 36, 10838]). Size of the model: 7186006\n"
     ]
    }
   ],
   "source": [
    "print(\"My max output: {0}. Shape: {1}. Size of the model: {2}\".format(my_out.max(), my_out.shape, calculate_params(my_decoder)))\n",
    "print(\"Their max output: {0}. Shape: {1}. Size of the model: {2}\".format(their_out.max(), my_out.shape, calculate_params(their_decoder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b74885-6f81-4644-9b5a-48a9a534fafd",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55bfd136-eae5-4edf-9d72-3d5a0029791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transformer = myTransformer(SRC_VOCAB_SIZE, TRG_VOCAB_SIZE, SRC_PAD_INDX, TRG_PAD_INDX, EMBED_SIZE, NUM_LAYERS, FORWARD_EXPANSION, HEADS, DROPOUT, DEVICE, MAX_LENGTH)\n",
    "treir_transformer = Transformer(SRC_VOCAB_SIZE, TRG_VOCAB_SIZE, SRC_PAD_INDX, TRG_PAD_INDX, EMBED_SIZE, NUM_LAYERS, FORWARD_EXPANSION, HEADS, DROPOUT, DEVICE, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f3edc5c-ed0d-40b5-9094-944fd14e996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_out = my_transformer(de_trans, en_trans)\n",
    "their_out = treir_transformer(de_trans, en_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7018c4e1-5dbe-47d3-832c-04196b046f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My max output: 2.9482316970825195. Shape: torch.Size([128, 36, 10838]). Size of the model: 13523894\n",
      "Their max output: 3.751157760620117. Shape: torch.Size([128, 36, 10838]). Size of the model: 13523030\n"
     ]
    }
   ],
   "source": [
    "print(\"My max output: {0}. Shape: {1}. Size of the model: {2}\".format(my_out.max(), my_out.shape, calculate_params(my_transformer)))\n",
    "print(\"Their max output: {0}. Shape: {1}. Size of the model: {2}\".format(their_out.max(), my_out.shape, calculate_params(treir_transformer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570d4aff-db75-4bd4-b857-132c356c80b9",
   "metadata": {},
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7d413e5-af97-4d68-9a7a-ac703852dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 3e-4\n",
    "NUM_LAYERS = 3\n",
    "HEADS = 8\n",
    "EMBED_SIZE = 512\n",
    "FORWARD_EXPANSION = 4\n",
    "DROPOUT = 0.1\n",
    "DEVICE = \"cpu\"\n",
    "MAX_LENGTH = 100\n",
    "\n",
    "transformer = myTransformer(SRC_VOCAB_SIZE, TRG_VOCAB_SIZE, SRC_PAD_INDX, TRG_PAD_INDX, EMBED_SIZE, NUM_LAYERS, FORWARD_EXPANSION, HEADS, DROPOUT, DEVICE, MAX_LENGTH)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), LEARNING_RATE)\n",
    "transformer.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2275a662-8b6d-44f4-90d1-d7054ac06dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"checkpoint.pth\"\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')\n",
    "transformer.load_state_dict(checkpoint[\"state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4352c8aa-17e1-49cf-9a3d-3ef25215110c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8a909-4a0a-440e-912e-5e86253d8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Forward example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c750e66b-e620-464c-b9f1-8a702b774bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = transformer(de_trans, en_trans[:, :-1])\n",
    "out = torch.softmax(out, dim=2)\n",
    "out = out.argmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09f9c3e7-eecf-4b61-b80f-b605adf89265",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_id = 1\n",
    "example_de = [de_vocab.lookup_token(idx) for idx in de_trans[example_id]]\n",
    "example_en = [en_vocab.lookup_token(idx) for idx in en_trans[example_id]]\n",
    "example_out_en = [en_vocab.lookup_token(idx) for idx in out[example_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c76b3-e315-4d9b-8a6b-c11eada5da0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e190f61-625b-453a-9d20-e9723ab378ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "126377f9-6472-4108-9e6c-b4a5bd0f419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_token = en_vocab.lookup_indices([\"<bos>\"])\n",
    "sentence = bos_token\n",
    "de_input = de_trans[example_id].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "830c984d-39ac-4e10-9e75-aa953bbc077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 0: tensor([[20]])\n",
      "STEP 1: tensor([[ 20, 118]])\n",
      "STEP 2: tensor([[ 20, 118, 426]])\n",
      "STEP 3: tensor([[ 20, 118, 426,  48]])\n",
      "STEP 4: tensor([[ 20, 118, 426,  48,   8]])\n",
      "STEP 5: tensor([[ 20, 118, 426,  48,   8,   4]])\n",
      "STEP 6: tensor([[ 20, 118, 426,  48,   8,   4, 326]])\n",
      "STEP 7: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6]])\n",
      "STEP 8: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5]])\n",
      "STEP 9: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3]])\n",
      "STEP 10: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6]])\n",
      "STEP 11: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5]])\n",
      "STEP 12: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3]])\n",
      "STEP 13: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6]])\n",
      "STEP 14: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5]])\n",
      "STEP 15: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3]])\n",
      "STEP 16: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6]])\n",
      "STEP 17: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5]])\n",
      "STEP 18: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3]])\n",
      "STEP 19: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3,   6]])\n",
      "STEP 20: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3,   6,   5]])\n",
      "STEP 21: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3,   6,   5,   3]])\n",
      "STEP 22: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3,   6,   5,   3,   6]])\n",
      "STEP 23: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3,   6,   5,   3,   6,   5]])\n",
      "STEP 24: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3,   6,   5,   3,   6,   5,   3]])\n",
      "STEP 25: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3,   6,   5,   3,   6,   5,   3,   6]])\n",
      "STEP 26: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3,   6,   5,   3,   6,   5,   3,   6,   5]])\n",
      "STEP 27: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3,   6,   5,   3,   6,   5,   3,   6,   5,   3]])\n",
      "STEP 28: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3,   6,   5,   3,   6,   5,   3,   6,   5,   3,\n",
      "           6]])\n",
      "STEP 29: tensor([[ 20, 118, 426,  48,   8,   4, 326,   6,   5,   3,   6,   5,   3,   6,\n",
      "           5,   3,   6,   5,   3,   6,   5,   3,   6,   5,   3,   6,   5,   3,\n",
      "           6,   5]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    sentence_tensor = torch.LongTensor(sentence).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        out = transformer(de_input, sentence_tensor)\n",
    "        \n",
    "    out = out.argmax(dim=2)\n",
    "    print(f\"STEP {i}: {out}\")\n",
    "    sentence.append(out[0][-1].item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc84ce-5326-445c-8beb-df29e3e59b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e9b85af4-ec19-4eae-8aa3-d73784d7ffaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>',\n",
       " 'Two',\n",
       " 'dogs',\n",
       " 'drink',\n",
       " 'water',\n",
       " 'in',\n",
       " 'a',\n",
       " 'lake',\n",
       " '.',\n",
       " '\\n',\n",
       " '<eos>',\n",
       " '.',\n",
       " '\\n',\n",
       " '<eos>',\n",
       " '.',\n",
       " '\\n',\n",
       " '<eos>',\n",
       " '.',\n",
       " '\\n',\n",
       " '<eos>',\n",
       " '.',\n",
       " '\\n',\n",
       " '<eos>',\n",
       " '.',\n",
       " '\\n',\n",
       " '<eos>',\n",
       " '.',\n",
       " '\\n',\n",
       " '<eos>',\n",
       " '.',\n",
       " '\\n']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[en_vocab.lookup_token(idx) for idx in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206d1d0-e2bb-44f3-bf9b-8a98e3c61193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
